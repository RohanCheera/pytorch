{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## What is PyTorch?  \n",
        "* PyTorch is an open-source machine learning library developed by Facebook's\n",
        "AI Research lab. Itâ€™s popular for its flexibility, ease of use, and dynamic computational graph, making it a favorite among researchers and developers alike.\n",
        "## Why PyTorch?\n",
        "* Dynamic Computational Graph: Allows you to change the network architecture during runtime.\n",
        "* Pythonic: Easy to learn and integrate with Python's scientific libraries.\n",
        "Strong community support and extensive documentation."
      ],
      "metadata": {
        "id": "zRJt5GwPW2MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=1\n",
        "type(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2biGqJ9MW1jd",
        "outputId": "91e15b97-af86-42bd-bde0-db13653d43e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "beAkbFQfU9sy"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=torch.tensor(x)\n",
        "type(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOaBp7EOYkVT",
        "outputId": "213f0c62-9e25-4eb5-b337-8de93c45ea46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.is_tensor(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnfOJ-1TYqrR",
        "outputId": "724c94ec-1d5a-4756-8e45-cfb9d63ba01d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.is_tensor(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-YSjx0uYzVC",
        "outputId": "300a6c7c-3bbb-43f8-cce3-f5a18978778b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Tensor?\n",
        "* A tensor is a fundamental data structure in PyTorch (and other machine learning frameworks like TensorFlow). Tensors are generalizations of matrices and vectors and can be thought of as multi-dimensional arrays. They are the primary way data is represented and manipulated in deep learning.\n",
        "\n",
        "## What are the advantages of tensor over vectors?\n",
        "\n",
        "* Tensors and vectors are both mathematical objects used to represent data, but tensors have several advantages over vectors, especially in the context of machine learning and deep learning. Here are some of the key advantages of tensors over vectors:\n",
        "\n",
        "1. **Higher Dimensional Representation:**   \n",
        "Flexibility in Data Representation:\n",
        "Vectors are inherently one-dimensional, which means they can only represent a sequence of values. Tensors, on the other hand, can represent data in multiple dimensions. For example, while a vector can represent a simple list of numbers (like a row of pixels), a tensor can represent more complex structures like images (2D), videos (3D), or even higher-dimensional data.  \n",
        "``Complex Data Structures:``\n",
        "Tensors can model complex data structures that go beyond what vectors can represent. For example, an RGB image (which has height, width, and color channels) is naturally represented as a 3D tensor, not just a vector.\n",
        "2. **Generalized Operations:**  \n",
        "``Matrix Operations:``\n",
        "Tensors allow for generalized mathematical operations across different dimensions. While vectors are limited to operations like dot products or element-wise operations, tensors can handle more complex operations like matrix multiplication, tensor contractions, and convolutions.  \n",
        "``Batch Processing:``\n",
        "Tensors can represent batches of data (e.g., a batch of images in a 4D tensor with dimensions [batch_size, height, width, channels]). This allows for efficient parallel processing, which is crucial in deep learning.\n",
        "3. **Automatic Differentiation:**\n",
        "Gradient Computation:\n",
        "In machine learning frameworks like PyTorch, tensors support automatic differentiation, which means that gradients can be computed automatically during backpropagation. This feature is essential for training neural networks, where gradients are used to update model parameters. Vectors alone do not inherently support this functionality.\n",
        "4. **Device Flexibility:**  \n",
        "``GPU Acceleration:``\n",
        "Tensors can be moved to and processed on GPUs, allowing for significant speedups in computation. Vectors, typically implemented in simpler data structures like lists or arrays, don't have this built-in capability. The ability to move tensors between CPU and GPU devices seamlessly is a key advantage in deep learning tasks.\n",
        "5. **Consistency Across Different Data Types:**   \n",
        "``Unified Framework:``\n",
        "Tensors provide a consistent way to represent various data types (scalars, vectors, matrices, and higher-dimensional data) within a single framework. This consistency simplifies the process of building and debugging machine learning models, as you don't have to switch between different data structures.\n",
        "6. **Advanced Indexing and Manipulation:**  \n",
        "``Slicing and Indexing:``\n",
        "Tensors support advanced indexing and slicing operations that go beyond what is typically done with vectors. You can easily access and manipulate specific dimensions or sub-tensors, which is crucial when working with multi-dimensional data.  \n",
        "``Broadcasting:``\n",
        "Tensors in frameworks like PyTorch support broadcasting, a mechanism that allows operations on tensors of different shapes in a way that would be impossible with traditional vectors.\n",
        "7. **Support for Various Data Types and Operations:**   \n",
        "Different Data Types:\n",
        "Tensors can store different data types such as float, int, and bool, and they support a wide range of mathematical and logical operations. Vectors are often limited in this regard, especially when implemented as basic arrays or lists in languages like Python.\n",
        "**Summary:**\n",
        "While vectors are useful for representing simple one-dimensional data, tensors offer greater flexibility, efficiency, and power by allowing for higher-dimensional representations, automatic differentiation, GPU acceleration, and advanced mathematical operations. These advantages make tensors indispensable in the context of deep learning and other complex computational tasks."
      ],
      "metadata": {
        "id": "6UNsb5CHZWRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create a complex tensor\n",
        "complex_tensor = torch.tensor([1 + 2j, 3 + 4j, 5 + 6j])\n",
        "\n",
        "# Check if the tensor is a complex tensor\n",
        "is_complex = torch.is_complex(complex_tensor)\n",
        "\n",
        "print(is_complex)  # Output: True\n",
        "\n",
        "# Create a regular (non-complex) tensor\n",
        "real_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "# Check if the tensor is a complex tensor\n",
        "is_complex = torch.is_complex(real_tensor)\n",
        "\n",
        "print(is_complex)  # Output: False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq0suCeJfLrf",
        "outputId": "59507ab0-8c15-4292-ba18-7bad604ec6dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create a complex tensor\n",
        "tensor = torch.tensor([1 + 2j, 3 + 4j, 5 + 6j])\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eouYArJZUmm",
        "outputId": "b683d613-302a-44c6-e6da-8fc0c48b787d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.+2.j, 3.+4.j, 5.+6.j])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check if the tensor is conjugated (it won't be by default)\n",
        "is_conjugated = torch.is_conj(tensor)\n",
        "\n",
        "print(is_conjugated)  # Output: False\n",
        "\n",
        "# Conjugate the tensor\n",
        "conjugated_tensor = tensor.conj()\n",
        "print(conjugated_tensor)\n",
        "# Check if the conjugated tensor is marked as conjugated\n",
        "is_conjugated = torch.is_conj(conjugated_tensor)\n",
        "\n",
        "print(is_conjugated)  # Output: True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN7pROQhY4X2",
        "outputId": "a9c9ccd6-9600-4cfa-afe4-a57bb79f9971"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "tensor([1.-2.j, 3.-4.j, 5.-6.j])\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.is_floating_point(torch.tensor(1.0000000000000000000000000000000000000000000000000000000001))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9fCb9BWY3DR",
        "outputId": "a44af868-79ea-40ef-a067-1fecac8f08c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}